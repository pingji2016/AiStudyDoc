**LoRA**（Low-Rank Adaptation，低秩自适应）是一种用于高效微调大型预训练模型（尤其是大语言模型）的技术，由微软的研究团队在2021年提出。它的核心目标是在保持模型原有性能的同时，大幅降低微调所需的计算资源和存储开销。

### **1. 核心思想**
- **问题**：传统微调需要更新整个模型的参数（可能包含数十亿甚至万亿参数），计算成本极高。
- **LoRA的解决方案**：
  - **冻结预训练模型**：保持原始参数不变，避免梯度计算和存储开销。
  - **注入低秩矩阵**：在模型的特定层（如注意力层的查询Q、键K、值V矩阵）旁添加两个小型可训练矩阵（通常为低秩矩阵），通过矩阵相乘模拟参数更新的效果。
  - **数学表达**：  
    原始层输出：`h = Wx`  
    LoRA微调后：`h = Wx + BAx`  
    其中 `W` 是冻结的原始权重，`A` 和 `B` 是可训练的低秩矩阵（秩 `r` 远小于模型维度），`BA` 构成对 `W` 的低秩近似更新。

### **2. 关键特点**
- **参数高效**：仅需训练注入的低秩矩阵（通常不到原模型参数的1%），例如微调一个70亿参数的模型可能只需几百万可训练参数。
- **存储友好**：多个下游任务可以共享同一个预训练模型，只需保存不同的低秩矩阵，节省存储空间。
- **训练加速**：由于参数大幅减少，训练速度更快，显存需求降低。
- **部署灵活**：微调后的模型可通过合并权重（`W' = W + BA`）导出为独立模型，无需额外推理开销。

### **3. 应用场景**
- **大语言模型（LLM）适配**：如使用LoRA微调LLaMA、GPT等模型适应特定任务（文本生成、对话、代码生成等）。
- **跨模态模型**：微调CLIP、Stable Diffusion等模型，例如在保持画风一致性的情况下训练图像生成模型。
- **资源受限环境**：允许在消费级GPU上微调大型模型。

### **4. 典型工作流程**
1. **选择适配层**：通常针对Transformer中的注意力矩阵（Q、K、V、FFN层）。
2. **设定秩（r）**：秩 `r` 是超参数，取值较小（如4、8、16），平衡效果与效率。
3. **训练低秩矩阵**：在任务数据上仅训练 `A` 和 `B` 矩阵，保持原模型冻结。
4. **合并权重（可选）**：将 `W` 与 `BA` 相加得到新权重，用于推理部署。

### **5. 扩展与变体**
- **QLoRA**：结合量化技术，进一步降低显存需求，实现更高参数规模模型的微调。
- **AdaLoRA**：动态调整秩分配，优化参数效率。
- **多任务适配**：为不同任务训练独立的LoRA模块，快速切换任务。

### **举例说明**
在微调ChatGLM或LLaMA时，使用LoRA可能只需训练0.1%的参数（如100万个参数），即可使模型适应医疗问答或法律文档生成任务，而传统全参数微调需要更新全部数百亿参数。

### **优势与局限性**
- **优势**：高效、轻量、易于部署，适合中小团队或个人开发者。
- **局限性**：低秩近似可能无法完全捕捉复杂任务的全部信息，超参数（如秩、适配层选择）需要调优。

总之，**LoRA是一种通过低秩矩阵分解实现参数高效微调的方法**，已成为大模型轻量化适配的主流技术之一，推动了AI技术的民主化应用。